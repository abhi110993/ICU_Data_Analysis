{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM,CuDNNLSTM\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: 1558  1024 Y dimension:1558\n",
      "Abnormal: 461  1024 Y dimension:461\n"
     ]
    }
   ],
   "source": [
    "xnormal = []\n",
    "ynormal = []\n",
    "\n",
    "\n",
    "# Reading HeartRate data for Normal Patients\n",
    "#f = \n",
    "#f = \n",
    "#f = \n",
    "f = [open(\"./NormalData/OxygenSaturation.csv\", \"r\"), open(\"./NormalData/HeartRate.csv\", \"r\"), open(\"./NormalData/BloodPressure.csv\", \"r\"), open(\"./NormalData/RespiratoryRate.csv\", \"r\")]\n",
    "\n",
    "\n",
    "s1=f[0].readline()\n",
    "s2=f[1].readline()\n",
    "s3=f[2].readline()\n",
    "s4=f[3].readline()\n",
    "\n",
    "\n",
    "#print(s1)\n",
    "#print(s2)\n",
    "#print(s3)\n",
    "#print(s4)\n",
    "while s1!=\"\":\n",
    "    a = []\n",
    "    b=s1.split(',')\n",
    "    for i in range(0, len(b)):\n",
    "        a.append(float(b[i]))\n",
    "        #print(b[i])\n",
    "        #print(\"a=\"+str(a))\n",
    "    b=s2.split(',')\n",
    "    for i in range(0, len(b)):\n",
    "        a.append(float(b[i]))\n",
    "    b=s3.split(',')\n",
    "    for i in range(0, len(b)):\n",
    "        a.append(float(b[i]))\n",
    "    b=s4.split(',')\n",
    "    for i in range(0, len(b)):\n",
    "        a.append(float(b[i]))\n",
    "    xnormal.append(a)\n",
    "    ynormal.append(0)\n",
    "    #print(len(a))\n",
    "    s1=f[0].readline()\n",
    "    s2=f[1].readline()\n",
    "    s3=f[2].readline()\n",
    "    s4=f[3].readline()\n",
    "    \n",
    "\n",
    "print(\"Normal: \"+str(len(xnormal))+\"  \"+str(len(xnormal[0]))+\" Y dimension:\"+str(len(ynormal)))    \n",
    "\n",
    "f = [open(\"./AbnormalData/OxygenSaturation.csv\", \"r\"), open(\"./AbnormalData/HeartRate.csv\", \"r\"), open(\"./AbnormalData/BloodPressure.csv\", \"r\"), open(\"./AbnormalData/RespiratoryRate.csv\", \"r\")]\n",
    "\n",
    "xAbnormal=[]\n",
    "yAbnormal=[]\n",
    "\n",
    "s1=f[0].readline()\n",
    "s2=f[1].readline()\n",
    "s3=f[2].readline()\n",
    "s4=f[3].readline()\n",
    "\n",
    "\n",
    "#print(s1)\n",
    "#print(s2)\n",
    "#print(s3)\n",
    "#print(s4)\n",
    "while s1!=\"\":\n",
    "    a = []\n",
    "    b=s1.split(',')\n",
    "    for i in range(0, len(b)):\n",
    "        a.append(float(b[i]))\n",
    "        #print(b[i])\n",
    "        #print(\"a=\"+str(a))\n",
    "    b=s2.split(',')\n",
    "    for i in range(0, len(b)):\n",
    "        a.append(float(b[i]))\n",
    "    b=s3.split(',')\n",
    "    for i in range(0, len(b)):\n",
    "        a.append(float(b[i]))\n",
    "    b=s4.split(',')\n",
    "    for i in range(0, len(b)):\n",
    "        a.append(float(b[i]))\n",
    "    xAbnormal.append(a)\n",
    "    yAbnormal.append(1)\n",
    "    #print(len(a))\n",
    "    s1=f[0].readline()\n",
    "    s2=f[1].readline()\n",
    "    s3=f[2].readline()\n",
    "    s4=f[3].readline()\n",
    "    \n",
    "\n",
    "print(\"Abnormal: \"+str(len(xAbnormal))+\"  \"+str(len(xAbnormal[0]))+\" Y dimension:\"+str(len(yAbnormal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461  1024 Y dimension:461\n",
      "921  1024 Y dimension:921\n"
     ]
    }
   ],
   "source": [
    "cTrainx=[] # current train x data\n",
    "cTrainy=[] # current test y data\n",
    "\n",
    "for i in range(0, 461):\n",
    "    cTrainx.append(xnormal[i])\n",
    "    cTrainy.append(ynormal[i])\n",
    "print(str(len(cTrainx))+\"  \"+str(len(cTrainx[0]))+\" Y dimension:\"+str(len(cTrainy)))\n",
    "i=0\n",
    "for i in range(0, 460):\n",
    "    cTrainx.append(xAbnormal[i])\n",
    "    cTrainy.append(yAbnormal[i])\n",
    "print(str(len(cTrainx))+\"  \"+str(len(cTrainx[0]))+\" Y dimension:\"+str(len(cTrainy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(921, 1024)\n",
      "(921, 1024, 1)\n",
      "(921,)\n"
     ]
    }
   ],
   "source": [
    "# List to numpy array conversion\n",
    "y=np.transpose(cTrainy)\n",
    "x = np.array(cTrainx)\n",
    "print(x.shape)\n",
    "x = x.reshape(len(x),len(x[0]),1);\n",
    "print(x.shape)\n",
    "#print(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(736, 1024, 1)\n",
      "(736,)\n",
      "Total normal data after distribution: 381\n",
      "Total Abnormal data: 355\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=50)\n",
    "x_train = tf.keras.utils.normalize(X_train, axis=0)\n",
    "x_test = tf.keras.utils.normalize(X_test, axis=0)\n",
    "print(x_train.shape)\n",
    "#print(x_train)\n",
    "#y_train=np.array([1,1])\n",
    "print(y_train.shape)\n",
    "#print(y_train)\n",
    "count=0\n",
    "for op in y_train:\n",
    "    if(op==1):\n",
    "        count+=1\n",
    "print(\"Total normal data after distribution: \"+str(len(y_train)-count)+\"\\nTotal Abnormal data: \"+str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(737, 1024, 1)\n",
      "(1024, 1)\n",
      "Input shape\n",
      "(1024, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_train[0].shape)\n",
    "\n",
    "model = Sequential()\n",
    "print(\"Input shape\")\n",
    "print(x_train.shape[1:])\n",
    "\n",
    "#model.add(LSTM(1024, input_shape=(x_train.shape[1:]), activation='relu', return_sequences=True))\n",
    "\n",
    "model.add(CuDNNLSTM(256, input_shape=(x_train.shape[1:]), return_sequences=True))\n",
    "\n",
    "#model.add(CuDNNLSTM(256))\n",
    "#model.add(CuDNNLSTM(256, input_shape=(x_train.shape[1:]), return_sequences=True))\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.01, decay=1e-5)\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 737 samples, validate on 185 samples\n",
      "Epoch 1/3\n",
      "737/737 [==============================] - 3s 4ms/sample - loss: 1.2593 - acc: 0.5020 - val_loss: 0.8040 - val_acc: 0.4324\n",
      "Epoch 2/3\n",
      "737/737 [==============================] - 3s 4ms/sample - loss: 0.8384 - acc: 0.4830 - val_loss: 0.7196 - val_acc: 0.5676\n",
      "Epoch 3/3\n",
      "737/737 [==============================] - 3s 4ms/sample - loss: 0.7413 - acc: 0.5088 - val_loss: 0.8247 - val_acc: 0.4324\n",
      "Train on 737 samples, validate on 185 samples\n",
      "Epoch 1/3\n",
      "737/737 [==============================] - 3s 4ms/sample - loss: 0.7400 - acc: 0.4898 - val_loss: 0.7114 - val_acc: 0.4324\n",
      "Epoch 2/3\n",
      "737/737 [==============================] - 3s 4ms/sample - loss: 0.7034 - acc: 0.4925 - val_loss: 1.3121 - val_acc: 0.4324\n",
      "Epoch 3/3\n",
      "737/737 [==============================] - 3s 4ms/sample - loss: 1.0028 - acc: 0.5061 - val_loss: 0.7374 - val_acc: 0.4324\n",
      "Train on 737 samples, validate on 185 samples\n",
      "Epoch 1/3\n",
      "737/737 [==============================] - 3s 4ms/sample - loss: 0.7950 - acc: 0.4925 - val_loss: 0.7206 - val_acc: 0.5676\n",
      "Epoch 2/3\n",
      "737/737 [==============================] - 3s 4ms/sample - loss: 0.7930 - acc: 0.4912 - val_loss: 0.7188 - val_acc: 0.4324\n",
      "Epoch 3/3\n",
      "737/737 [==============================] - 3s 4ms/sample - loss: 0.7511 - acc: 0.5319 - val_loss: 0.7144 - val_acc: 0.4324\n"
     ]
    }
   ],
   "source": [
    "for j in range(0, 3):\n",
    "    cTrainx=[] # current train x data\n",
    "    cTrainy=[] # current test y data\n",
    "\n",
    "    for i in range(0, 461):\n",
    "        cTrainx.append(xnormal[i+j*461])\n",
    "        cTrainy.append(ynormal[i+j*461])\n",
    "    #print(str(len(cTrainx))+\"  \"+str(len(cTrainx[0]))+\" Y dimension:\"+str(len(cTrainy)))\n",
    "    i=0\n",
    "    for i in range(0, 461):\n",
    "        cTrainx.append(xAbnormal[i])\n",
    "        cTrainy.append(yAbnormal[i])\n",
    "    #print(str(len(cTrainx))+\"  \"+str(len(cTrainx[0]))+\" Y dimension:\"+str(len(cTrainy)))\n",
    "\n",
    "    # List to numpy array conversion\n",
    "    y=np.transpose(cTrainy)\n",
    "    x = np.array(cTrainx)\n",
    "    x = x.reshape(len(x),len(x[0]),1);\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=50)\n",
    "    x_train = tf.keras.utils.normalize(X_train, axis=0)\n",
    "    x_test = tf.keras.utils.normalize(X_test, axis=0)\n",
    "    count=0\n",
    "    for op in y_train:\n",
    "        if(op==1):\n",
    "            count+=1\n",
    "\n",
    "    model.fit(x_train,\n",
    "              y_train,\n",
    "              epochs=3,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
