{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1558  256\n",
      "(2019, 256)\n",
      "(2019, 1, 256)\n",
      "[[[ 77.5  79.   78.  ...  79.   79.   80. ]]\n",
      "\n",
      " [[ 69.   69.   69.  ...  58.   58.   58. ]]\n",
      "\n",
      " [[ 95.5  94.   93.  ...  90.   91.   90. ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 79.   79.   79.  ...  86.   86.   85. ]]\n",
      "\n",
      " [[113.  113.  107.5 ... 118.  120.  116. ]]\n",
      "\n",
      " [[ 66.   69.   68.  ...  81.   84.   88. ]]]\n",
      "(2019,)\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "\n",
    "# Reading HeartRate data for Normal Patients\n",
    "f = open(\"./NormalData/HeartRate.csv\", \"r\")\n",
    "s=f.readline()\n",
    "while s!=\"\":\n",
    "    a = s.split(',')\n",
    "    for i in range(0, len(a)): \n",
    "        a[i] = float(a[i]) \n",
    "    x.append(a)\n",
    "    y.append(0)\n",
    "    s=f.readline()\n",
    "\n",
    "    \n",
    "print(str(len(x))+\"  \"+str(len(x[0])))\n",
    "\n",
    "# Reading HeartRate data for Abnormal Patients\n",
    "f = open(\"./AbnormalData/HeartRate.csv\", \"r\")\n",
    "s=f.readline()\n",
    "while s!=\"\":\n",
    "    a = s.split(',')\n",
    "    for i in range(0, len(a)): \n",
    "        a[i] = float(a[i]) \n",
    "    x.append(a)\n",
    "    y.append(1)\n",
    "    s=f.readline()\n",
    "\n",
    "\n",
    "y=np.transpose(y)\n",
    "x = np.array(x)\n",
    "print(x.shape)\n",
    "x = x.reshape(len(x),1,len(x[0]));\n",
    "#x = x.reshape(len(x),len(x[0]),1);\n",
    "print(x.shape)\n",
    "print(x)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "\n",
    "#mnist = tf.keras.datasets.mnist\n",
    "\n",
    "#(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train[0])\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1009, 1, 256)\n",
      "(1009,)\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.utils.normalize(X_train, axis=0)\n",
    "x_test = tf.keras.utils.normalize(X_test, axis=0)\n",
    "print(x_train.shape)\n",
    "#print(x_train)\n",
    "#y_train=np.array([1,1])\n",
    "print(y_train.shape)\n",
    "print(y_train)\n",
    "\n",
    "\n",
    "#print(x_test.shape)\n",
    "#print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0925 16:13:35.712788 13928 deprecation.py:506] From C:\\Users\\sabhi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#First layer\n",
    "model.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu))\n",
    "#Second Layer\n",
    "model.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu))\n",
    "'''\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Output Layer\n",
    "model.add(tf.keras.layers.Dense(2, activation=\"sigmoid\"))\n",
    "# 2 no. of outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0925 16:13:36.076986 13928 deprecation.py:323] From C:\\Users\\sabhi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 121ms/sample - loss: 0.9412 - acc: 0.5000\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 997us/sample - loss: 0.8564 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 997us/sample - loss: 0.7760 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 996us/sample - loss: 0.7003 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 997us/sample - loss: 0.6292 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 1ms/sample - loss: 0.5630 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 998us/sample - loss: 0.5017 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 997us/sample - loss: 0.4454 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 980us/sample - loss: 0.3940 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 1ms/sample - loss: 0.3476 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 997us/sample - loss: 0.3060 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 498us/sample - loss: 0.2689 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 998us/sample - loss: 0.2361 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 1ms/sample - loss: 0.2073 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 1ms/sample - loss: 0.1822 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 997us/sample - loss: 0.1603 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 980us/sample - loss: 0.1413 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 993us/sample - loss: 0.1250 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 1ms/sample - loss: 0.1108 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 499us/sample - loss: 0.0986 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 997us/sample - loss: 0.0881 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 997us/sample - loss: 0.0790 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 1ms/sample - loss: 0.0712 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 996us/sample - loss: 0.0644 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 982us/sample - loss: 0.0585 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 997us/sample - loss: 0.0534 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 1ms/sample - loss: 0.0489 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 980us/sample - loss: 0.0450 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0416 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 499us/sample - loss: 0.0386 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 1ms/sample - loss: 0.0359 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 997us/sample - loss: 0.0335 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 1ms/sample - loss: 0.0314 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 994us/sample - loss: 0.0296 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 1ms/sample - loss: 0.0279 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 997us/sample - loss: 0.0264 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 987us/sample - loss: 0.0250 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 998us/sample - loss: 0.0238 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 995us/sample - loss: 0.0227 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 1ms/sample - loss: 0.0217 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 1ms/sample - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 997us/sample - loss: 0.0200 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 1ms/sample - loss: 0.0192 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 997us/sample - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 997us/sample - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 498us/sample - loss: 0.0173 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 997us/sample - loss: 0.0167 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 499us/sample - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 1ms/sample - loss: 0.0153 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20fb3d1a8d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017/2017 [==============================] - 0s 39us/sample - loss: 0.7429 - acc: 0.2286\n",
      "0.742949117867144\n",
      "0.22855726\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(val_loss)\n",
    "print(val_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
